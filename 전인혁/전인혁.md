2021-02-23
-----
온비드 동산/기타자산 공고-> 공고목록란에서 공고에 해당하는 내용들을 크롤링하고, 공고에 해당하는 물건들을 클릭하여 물건에 대한 정보를 받아오는 프로그램또한 작업중에 있습니다. 내일까지 해보고 안되면, 서류화를 시작하겠습니다.

2021-02-22
-----
온비드 동산/기타자산 입찰결과 -> 물건입찰결과의 테이블의 각 tr을 방문하여 요약정보를 크롤링하고 입찰상세 버튼이 있으면 버튼을 클릭해 새 탭의 detail 데이터들을 크롤링합니다. 그리고 압류재산이거나 입찰상세 버튼이 없을경우를 제외하고는 물건번호를 클릭해 입찰이력을 방문해 회차.차수, 개찰일시를 비교해 일치하는것의 입찰번호를 크롤링합니다. 

2021-02-19
-----
온비드 홈페이지 동산/기타자산의 물건 입찰 결과의 한 로우의 데이터들을 읽고, 입찰상세 버튼이 존재하면 들어가 모든 데이터들을 읽습니다. 

2021-02-18
-----
온비드 홈페이지에서 동산/기타자산 물건입찰결과내용을 크롤링중입니다. 기존 물건정보를 받는것과 달리 모듈과 클래스를 활용하여 코드를 짜는 구상을 하는중이며, 검색 조건설정까지는 완료하였습니다.

2021-02-17
-----
온비드 동산/기타자산 물건세부정보 , 입찰정보  입찰이력, 해당공고 보기 내역들을 받아오는 것을 대략적으로 확인하였습니다. 입찰정보의 회차별 입찰 정보 중 공매재산명세 에 해당하는 파일을 받아오고 입찰결과의 내용들을 내일 받아올 예정입니다.

2021-02-16
-----
테이블의 엘리먼트가 존재 유무에 따라 테이블 마다 각 데이터를 받아오는 모듈을 개별적으로 만드는중이고, 유가증권의 템플릿이 일치하지 않는 경우가 있어 어떻게 처리해야할지 고민하였습니다.

2021-02-15
-----
테이블의 엘리먼트가 존재 유무에 따라 테이블 마다 각 데이터를 받아오는 모듈을 개별적으로 만드는중이고, 유가증권의 템플릿이 일치하지 않는 경우가 있어 어떻게 처리해야할지 고민중입니다.

2021-02-10
-----
기능별로 모듈을 나누고 클래스를 정리하기위해 의견을 나누던 중 파이썬 표준 라이브러리에 대한 이해도가 부족하여 더 나은 코드를 작성하지 못함을 느꼈습니다. 따라서 공식문서를 통해 표준 라이브러리의 종류를 대략적으로 파악하고 현재 사용중인 코드 스타일보다 나은 라이브러리나 혀재 사용중인 라이브러리를 좀 더 상황에 알맞게 사용할 수 있도록 re라이브러리 위주로 공부를 하였고 남은 연휴기간 동안 좀 더 공부 할 계획입니다.

2021-02-09
-----
온비드 동산/기타자산 권리/증권 의 물건세부정보와 입찰정보를 받아오는 것을 하였습니다. 한 파일안에 모든 클래스와 함수들을 정의한 탓에 코드가 상당히 복잡하고 불필요한 기능들이 섞여있어 기능별로 모듈을 나누고 클래스를 정리해야 할것 같습니다.

2021-02-08 [확인]
-----
자동차/운송장비 용도의 물건 세부 정보, 입찰 정보 등 모든 물건정보를 받아오는 것을 확인하였습니다. 물품(기계) 용도의 물건 세부 정보. 입찰 정보 등 모든 물건정보를 받아 오는 것을 확인하였습니다.  물품(기타) 용도의 물건 세부 정보, 입찰 정보 등 모든 물건정보를 받아 오는 것을 확인하였습니다. 데이터는 다 받아왔지만 XPATH로 설정된것 , 유무 판별하느라 너무 느린것 , 중간에 element를 받지못해 종료되는 것을 수정하여야 합니다.

2021-02-05 [확인]
-----
온비드 홈페이지의 크롤링 진행 중 입찰 정보 테이블의 요소들을 받아오는 작업에서 요소들이 받아와지지 않는 문제가 발생하였는데 WebDriverWait메소드를 활용하여 값이 나올때까지 대기하는 코드를 짜 해결했습니다. 또한 검색 날짜를 1년으로 설정하도록 변경했고 webelement가 none값인지 판별하는 코드도 추가중에 있습니다.

2021-02-04 [확인]
-----
온비드 크롤링을 용도별로 루프를 돌게하여 모든 데이터 테이블을 훑는 것을 확인하였고, 용도별로 dictionary template 을 구별하고 함수또한 다르게 만들어 볼려고 하는중입니다. 

2021-02-03 [확인]
-----
온비드 홈페이지 동산/기타자산 데이터들을 크롤링하는 프로그램을 만드는중입니다.. 

2021-02-02 [확인]
-----
온비드 API응답값으로 이루어진 테이블 구조를 생각해보았습니다. 온비드 사이트의 동산/기타자산 크롤링을 명령 받고 기존 코드의 구조를 파악하고, 사이트의 데이터들이 어떻게 구성되었는지 한번 둘러보았습니다.

2021-02-01 [확인] 
-----
기존 DB의 값들과 API응답값들을 비교해보고 이전 API응답값들로 만들어진 데이터베이스 테이블 구조를 바꿔 보려고 생각중입니다.

2021-01-29 [확인]
-----
mysql 쿼리를 짜서 AUCLIST 테이블의 기존데이터와 api응답 데이터들을 비교해 보았지만 일치하지는 값도 있었지만 일치하지않는 값도 존재하였다. PD 테이블의 값은 기본정보 상세조회 테이블로 데이터들이 일치하는것을 확인하였다. GONGGO테이블의 값을 비교하기위해 캠코 공고공매물건조회서비스 API의 공매공고 기본정보 상세조회 데이터를 넣는 코드를 작성하였다.

2021-01-28 [확인]
-----
셀레니움을 활용하여 온비드 홈페이지의 물건 정보 중 물건 상세 정보 버튼 클릭시 나타나는 정보를 크롤링하고 입찰 버튼 정보 크롤링 진행중입니다. 또한 첨부파일을 클릭하여 받아오는 코드를 href 정보를 긁어오는 형태로 변경했습니다.                         
온비드 API명세로만든 테이블들의 칼럼과 기존 테이블의 칼럼값들을 대략적으로 모두 분류하였고, 데이터의 보다 정확한 비교를 하기위해 sql 쿼리 구현을 위해 구상중입니다. 

2021-01-27 [확인]
-----
지적도, 위치도 첨부파일이름을 원하는 값으로 변경하여 저장하였습니다. 또한 두 파일이 다수가 존재할때를 고려하여 코드를 변경하였습니다. 마지막으로 감정평가서의 파일이름을 받아오고 os 라이브러리를 사용하여 원하는 값으로 받아오는 작업을 진행중입니다.
기계및장비부품, 회원권및유가증권정보, 부동산 정보, 자동차및운송장비정보, 입찰이력정보, 이미지정보, 물건입찰정보, 물건 임대차정보테이블 내용들을 기존 온비드API명세로만든 테이블과 칼럼 이름 값등을 비교, 표시하였습니다.

2021-01-26 [확인]
-----
온비드 API 응답값들을 DB에 적재중이며 오늘 받은 기존 데이터베이스 구조를 파악하고 API요청 명세로 구성된 DB와 비교하여 비교방식을 고민중입니다.

2021-01-25 [확인]
-----
온비드 감정평가서정보, 임대차정보, 권리종류정보, 공매일정, 입찰이력, 주주정보, 법인현황정보 테이블 생성 및 코드 동작 확인했으며 tmux로 모두 데이터 적재중입니다.              
물건정보, 첨부파일 갯수, 입찰유형, 물건 상세정보의 dictionary 구조를 짜고 셀레니움을 통해 값을 받아와 동작이 됨을 확인했습니다. 또한 로그인 기능과 값을 받아올때 정규표현식을 사용하였습니다.

2021-01-22 [확인]
-----
Onbid 데이터베이스 적재를 위해 작업에 따라 클래스를 분류하고 기본정보 상세조회 오퍼레이션을 구성하고 있습니다.. 

2021-01-21 [확인]
-----
ONBID_UnifyUsageCltr_MAP 테이블을 생성하고 물건관리번호, 주소, X,Y좌표를 데이터를 추가하는 코드를 작성하였다. ONBID_UnifyUsageCltr 테이블의 데이터 넣는과정에서 오류가 있어서 코드를 수정하고 데이터를 처음부터 넣는중이다.

2021-01-20 [확인]
-----
python selenium webdriver Chrome 클래스와 chromedriver를 사용하여 온비드 홈페이지에 접속하고 팝업창을 닫은 뒤 find_element() method를 통해 부동산 HOME에 접속하여 정렬방법을 선택하고 페이지를 이동하여 순차적으로 부동산 데이터값을 크롤링하는 프로그램을 만들었습니다. 추가로 예외처리문을 작성할 예정입니다. 또한 온비드 물건정보 테이블에 계속해서 데이터를 적재중이고 두인경매, 온비드홈페이지와 API 응답값을 통해 물건관리번호를 어떤식으로 누락값을 찾을지 고민하고 있습니다.

2021-01-19 # 에이미파이(이선우) 확인
-----
온비드 코드조회서비스 API를 통해 받은 응답값을 ONBID_CategoryCode 테이블에 적재했습니다. 또한 온비드 물품정보조회 서비스의 9개 API 오퍼레이션중 7개의 테이블을 만들고 1개의 테이블은 데이터 적재중입니다. 마지막으로 셀레니움으로 온비드 홈페이지의 부동산 HOME에 접속하여 누락된 데이터값을 받아오는 작업을 진행할 예정입니다.

2021-01-18 # 에이미파이(이선우) 확인
-----
온비드 물건정보조회서비스 API를 통해 데이터를받아 적재하기위한 데이터베이스 구조를 짜고 통합용도별물건목록 조회서비스에 대한 테이블을 생성 및 통합용도별물건 기본 상세조회 분류를 위해 참고할 lookup table을 온비드 코드조회 서비스 API로 생성하였습니다. 또한 온비드 API명세와 응답값이 다른 경우가 생길 것을 대비해 DB의 칼럼을 생성하고 template을 수정하고 요청 쿼리를 수정하는 코드를 테스트해보았습니다.

2021-01-15 # 에이미파이(이선우) 확인
-----
프로젝트를 진행하며 만든 코드에서 urlib의 Request와 urlopen을 사용할 때 발생할 수 있는 예외처리와 API 서버에서 발생할 수 있는 예외처리, 응답값의 누락과 명세와 다른 포맷의 데이터값이 추가되어 들어오는 것에 대한 예외처리, 응답값의 타입이 다를때의 예외처리, 데이터베이스와의 연결에서 발생할 수 있는 예외처리를 해주었습니다. 또한 python Annotation을 사용하여 리팩토링중에 있습니다.

2021-01-14 # 에이미파이(이선우) 확인
-----
국토교통부 API의 12개 Operation의 공통점을 Base Class로 묶어 전처리단계로 법정동 코드 리스트와 계약년월 리스트, 시작점 설정 세개의 단계로 나누고 메인 단계로 법정동 코드와 계약년월로 URL을 요청하는 단계, API의 응답메시지의 result code로 부터 정상작동 판별단계, API 응답메시지에 명세값이 존재하는지 판별하는 단계, 응답 메시지 값 디비의 테이블에 저장하는 단계를 설정했습니다. 또한 메인 단계에서 발생하는 에러는 데이터베이스에 logging 했습니다. 이 후 tmux를 사용하여 데이터베이스에 적재 중이고 11개 오퍼레이션의 사용방법을 readme 파일에 정리하여 GitHub에 공유하였습니다.

2021-01-13 # 에이미파이(이선우) 확인
-----
response 결과값에 전용면적이 나오는 컬럼 옆에 PyungArea라는 컬럼을 만들고 전용면적 X 0.3025(평수 구하는 공식)을 코드에서 처리하도록 추가하였다. 요청명세와 다르게 response의 key 값이 누락된 경우를 해당 오퍼레이션의 dictionary template을 만들어 비교하여 key error를 처리해 주었다. 프로그램 실행중 예상치 못한 문제로 종료되었을때 재요청 시작값 설정

2021-01-12 # 에이미파이(이선우) 확인
-----
국토교통부_연립다세대 매매, 전월세 자료 , 단독/다가구 매매, 전월세 자료 , 상업업무용 부동산 매매 신고자료 테이블을 만들고 key 값에 대해 고민해 보았다. 프로그램의 서비스화를 위하여 readme.md 파일을 만들어 동작방법과 프로그램에 대한 정보를 제공하였다. 국토교통부 API의 11개 Operation의 공통 부분을 가지는 BaseClass를 만들었고 멀티 스레드를 활용하여 데이터베이스에 데이터를 넣을 때 연결이 끊기는 문제를 해결하기 위해 개선해 나가고 있습니다.

2021-01-11 # 에이미파이(이선우) 확인
-----
법정동 테이블에서 법정동 코드값을 받아서 URL을 설정하고 API를 요청한 뒤 응답값을 다시 데이터베이스에 저장하는 프로그램을 만들고 있습니다. 현재 만들어진 프로그램은 싱글 스레드로 인해 느린 동작속도와 api 요청 시 많은 오류가 발생하는 문제점이 있습니다. 그렇기에 멀티 스레드를 사용하고 api 요청 시 http status code에 따라 적절한 예외처리를 통해 효율적이고 안정적인 프로그램으로 바꿔나가고 있습니다. 또한 NSDI 데이터베이스의 테이블들 간의 관계도를 설정하고 객체 지향형태로 프로그램을 만들었습니다.

2021-01-08 # 에이미파이(이선우) 확인
-----
openApi 요청하고 데이터베이스에 적재하는데 엄청난 시간이 걸린다 openApi 요청시 timeout error 가 종종 발생해 이를 try catch 로 time.sleep(3)을 추가해 3초후에 다시 요청하게하여 프로그램의 중지를 멈추었다. 또한 시간이 오래걸리는것을 감안하여 수행률을 확인하고 현재 진행상황을 tqdm 모듈을 통해 시각적으로 표현하였다. 또한 작업의 효율을 올리기위해 tmux 프로그램을 사용하여 가상 서버에서 프로그램을 동작시키고 컴퓨터를 종류하여도 동작이 멈추지않고 진행하도록 하였다.

2021-01-07 # 에이미파이(이선우) 확인
-----
nsdi데이터베이스에 LandPriceAttribute, getIndvdHousingPriceAttr, getIndvdLandPriceAttr,LandPriceAttribute 테이블을 생성하였습니다.
국토교통부_표준지공시지가정보서비스, 국토교통부_공동주택가격정보서비스, 국토교통부_개별주택가격정보서비스, 국토교통부_개별공시지가정보서비스 각각에 해당하는 API를 요청하고 데이터들을 nsdi데이터베이스에 적재하였습니다.
서버를 이용하여 프로그램을 실행시켜보았습니다.

2021-01-06 # 에이미파이(이선우) 확인
-----
SEMAS_OpenAPI의 모든 Operation의 동작 여부를 확인하였고 DataBase에 적재 중 입니다.
표준지공시지가속성조회를 위한 룩업 테이블 bubjungdong을 생성하고 행정표준코드관리시스템에서 데이터의 변경이 있으면 이를 확인하여 존재여부를 갱신해주는 코드를 만들었습니다.
마지막으로 표준지공시지가속성조회 API의 출력값을 저장 할 LandPriceAttribute 테이블을 생성했습니다.

2021-01-05 # 에이미파이(이선우) 확인
-----
행정구역 API를 사용하여 상가업소번호, PNU코드, 건물관리번호, 상권번호, 좌표값들의 값들을 룩업테이블로 디비에 저장했습니다. 또한 전체적인 오퍼레이션의 틀을 완성시키고 워낙큰 데이터를 제외하고는 모두 성공적으로 db에 적재하였고, 나머지들은 차후에 마무리할 예정입니다. 또한 argparser를 이용해 사용자가 오퍼레이션 옵션을 선택할 수 있도록 main문을 수정하였습니다. 

2021-01-04 # 에이미파이(이선우) 확인
-----
재사용되는 코드를 효율적으로 사용하기 위해 전체적인 구조를 수정하여 클래스 형태로  바꿨습니다. 
또한 operation 4(storeZoneInAdmi),21(largeUpjongList),22(middleUpjongList),23(smallUpjongList) 들을 db에 적재하였습니다. 

2020-12-30 # 에이미파이(이선우) 확인
-----
디자인 패턴의 종류를 찾아보고 Singleton 패턴에 대하여 따로 공부했습니다.
python의 argparse 모듈 파트를 공부하였습니다.

2020-12-29 # 에이미파이(이선우) 확인
-----
OpenApi를 이용해 데이터를 parsing하고 그 데이터를 storeZoneOne 테이블에 데이터를 추가하는 코드를 작성하였다. 
storeZoneOne 테이블에 데이터들을 모두 넣고 mysql workbench를 이용해 확인하였다.cxy.csv파일에서 API가 동작하는 데이터값만 cxy_proper.csv로 저장했고storeZoneInRadius 오퍼레이션의 응답 메시지 명세값과 x축,y축,radius값을 가지는 storeZoneInRadiusAddxy 테이블을 생성했습니다. 이후 csv파일의 데이터값을 API의 요청값에 넣어 나온 응답 메시지를 디비에 저장하는 코드를 작성했습니다.

2020-12-28 # 에이미파이(이선우) 확인
-----
SEMAS_OpenAPI의 23개 Operation들을 MySQL Workbench를 사용하여 각각 Table로 생성했습니다.
Python에서 API를 효율적으로 활용하기위해 클래스로 나눠서 생성하는 것을 고민해보았고
응답메시지명세 값을 파라미터로 받아오도록 함수화해보았습니다.
마지막으로 Python에서 csv파일을 다루는 방법을 간단히 익혔습니다.

2020-12-24 # 에이미파이(이선우) 확인
-----
dev 데이터베이스에 저장될 operation table들의 data type을 팀원과 일치시켰습니다.
SEMAS_OpenAPI 활용 가이드를 읽어보고 operation들의 기능, 속성, data type, 코멘트 등등을 참조하여 mysql workbench 프로그램을 이용해 dev 데이터 베이스에 각 기능의 data를 저장하는 table을 생성하였습니다. 

2020-12-23 # 에이미파이(이선우) 확인
-----
공공데이터포털 오픈 API 상세의 Service key를 사용하는 Python 샘플코드를 참조하여
소상공인시장진흥공단_상가(상권)정보의 Operation을 사용하는 방법을 익혔습니다.
SEMAS_OpenAPI 활용 가이드를 참조하여 각 operation 테이블의 키값과 
각 테이블간의 관계와 룩업 테이블의 구상도를 생각 해보았습니다.
마지막으로 mysql workbench의 interface 조작이 어떤 query를 생성하는지 알아보았습니다.

2020-12-22 # 에이미파이(이선우) 확인
-----
업무의 커뮤니케이션을 위해 깃허브를 연결하였다. 업무에 사용될 DB 서버를 연결하고 API 사용법과 명세서를 간단히 전달받고 숙지 하였다. 
PyMySQL 모듈을 pip를 이용해 다운로드 하였고, 파이썬 코드로 mysql에 연결 하였다. API활용가이드 파일을 읽고 어떻게 프로그램을 구현해야할지 공부하였다.
